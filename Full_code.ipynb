{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66c0a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, RANSACRegressor, SGDRegressor, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa9a436",
   "metadata": {},
   "source": [
    "# Pobranie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b64d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "\n",
    "    def __init__(self, city, region, date=datetime.datetime.now().strftime(\"%B\")):\n",
    "        self.city = city\n",
    "        self.region = region\n",
    "        self.date = date\n",
    "    def get_links(self):\n",
    "        core_url = 'https://www.otodom.pl'\n",
    "        url = f'https://www.otodom.pl/pl/oferty/sprzedaz/mieszkanie/{self.city}/{self.region}'\n",
    "        n_of_offers = int(BeautifulSoup(requests.get(url).content, 'html.parser').find('span', class_=\"css-klxieh e1ia8j2v11\").getText())\n",
    "        n_of_pages = int(math.ceil(n_of_offers/36))\n",
    "        main_page_urls = [f'https://www.otodom.pl/pl/oferty/sprzedaz/mieszkanie/{self.city}/{self.region}?page={a}' for a in range(n_of_pages)]\n",
    "        \n",
    "        offers_links = []\n",
    "        for i in main_page_urls[: n_of_pages]:\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                page = requests.get(i)\n",
    "                soup = BeautifulSoup(page.content, 'html.parser')\n",
    "                for i in soup.find_all('div'):\n",
    "                    i = i.find_all('a')\n",
    "\n",
    "                    for a in i:\n",
    "                        offers_links.append(a.get('href'))\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "        offers_links = list(set(offers_links))\n",
    "        flats = []\n",
    "        for i in offers_links:\n",
    "            flat = re.findall(r'(/pl/oferta.*)', i)\n",
    "            flats.append(flat)\n",
    "        flats_updated = list(set([str(core_url) + i[0] for i in flats if len(i)>0]))\n",
    "        \n",
    "        return flats_updated\n",
    "    \n",
    "    def save_the_links(self):\n",
    "        with open(\"links_otodom_\"+ self.date +'_'+ self.city +'_'+ self.region + \".pickle\", \"wb\") as output_file:\n",
    "            pickle.dump(row_parameters.get_links(self), output_file)\n",
    "        return row_parameters.get_links(self)\n",
    "    def get_the_parameters(self):\n",
    "        try:    \n",
    "            with open(\"links_otodom_\"+ self.date +'_'+ self.city +'_'+ self.region + \".pickle\", \"rb\") as input_file:\n",
    "                urls = pickle.load(input_file)\n",
    "        except:\n",
    "            urls = row_parameters.save_the_links(self)\n",
    "        try:\n",
    "            with open(\"parameters_\"+ self.date +'_'+ self.city +'_'+ self.region + \".pickle\", \"rb\") as input_file:\n",
    "                parameters = pickle.load(input_file)\n",
    "            return parameters\n",
    "        except:\n",
    "            desc = []\n",
    "            prices = []\n",
    "            parameters = {'Powierzchnia': [], 'Liczba pokoi': [], 'Rynek': [], 'Rodzaj zabudowy': [], 'Piętro': [],\n",
    "                          'Ogrzewanie': [], 'Rok budowy': [], 'Stan wykończenia': [], 'Czynsz': [], 'Forma własności': [],\n",
    "                          'Materiał budynku':[], 'Cena':prices, 'Opis': desc, 'Lokalizacja': []}\n",
    "            for ofert in urls:\n",
    "                page = requests.get(ofert)\n",
    "                soup = BeautifulSoup(page.content, 'html.parser')\n",
    "                link_parms = {}\n",
    "\n",
    "                all_data = []\n",
    "                for data in soup.find_all('div', class_=\"css-1qzszy5 estckra8\"):\n",
    "                    all_data.append(data.getText())\n",
    "\n",
    "\n",
    "\n",
    "                price = re.findall(r'adPageHeaderPrice\">(.*)</strong><style data-emotion', str(soup))\n",
    "                all_data.append('Cena')\n",
    "                try:\n",
    "                    all_data.append(price[0]) \n",
    "                except:\n",
    "                    all_data.append(price)\n",
    "                for i in range(len(all_data)):\n",
    "                    if (i % 2) == 0:\n",
    "                        link_parms[all_data[i]] = all_data[i+1]\n",
    "\n",
    "                for i in [i for i in parameters.keys() if i not in ['Opis']]:\n",
    "                    try:\n",
    "                        parameters[i].append(link_parms[i])\n",
    "                    except:\n",
    "                        parameters[i].append(np.nan)\n",
    "                price = re.findall(r'adPageHeaderPrice\">(.*)</strong><style data-emotion', str(soup))\n",
    "            parameters['Lokalizacja'] = self.region\n",
    "            parameters['Miasto'] = self.city\n",
    "\n",
    "            with open(\"parameters_\"+ self.date +'_'+ self.city +'_'+ self.region + \".pickle\", \"wb\") as output_file:\n",
    "                pickle.dump(parameters, output_file)\n",
    "            return parameters\n",
    "       \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb29bf",
   "metadata": {},
   "source": [
    "# Przygotowanie danych\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c3049b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prepare_the_data:\n",
    "    \n",
    "    def __init__(self, city=None, month=datetime.datetime.now().strftime(\"%B\")):\n",
    "        self.month = month\n",
    "        self.city = city if city is not None else ''\n",
    "    \n",
    "    def get_data(self):\n",
    "        try:\n",
    "            with open(\"cleaned_data_\"+ self.month +'_'+ self.city + \".pickle\", \"rb\") as input_file:\n",
    "                df = pickle.load(input_file)\n",
    "            return df\n",
    "        except: \n",
    "            files = [f for f in os.listdir() if f.startswith('parameters_'+self.month+'_'+self.city)]\n",
    "            df = pd.DataFrame()\n",
    "            for file in files:\n",
    "                with open(file, \"rb\") as input_file:\n",
    "                    parameters = pickle.load(input_file)\n",
    "                    del parameters['Opis']\n",
    "\n",
    "                df_parms = pd.DataFrame(parameters)\n",
    "                df = pd.concat([df, df_parms])\n",
    "            return self.clean_the_data(df)\n",
    "    def clean_the_data(self, data):\n",
    "        try:\n",
    "            with open(\"cleaned_data_\"+ self.month +'_'+ self.city + \".pickle\", \"wb\") as input_file:\n",
    "                    final_df = pickle.load(input_file)\n",
    "        except:\n",
    "            df = data\n",
    "            df = df.dropna(subset=['Powierzchnia','Piętro'])\n",
    "            df['Powierzchnia'] = df['Powierzchnia'].apply(lambda x: x[:-2].replace(' ','').replace(',','.').strip())               \n",
    "            df['Liczba pokoi'] = df['Liczba pokoi'].apply(lambda x: x.replace('więcej niż 10','10')).astype('int64')\n",
    "            df = df[df['Piętro'] !='zapytaj']\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            for i in df.columns:\n",
    "                for a in list(df[(df[i] == 'zapytaj')].index):\n",
    "                    df[i].iloc[a] = np.nan\n",
    "\n",
    "            for i in df.columns:\n",
    "                for a in list(df[(df[i] == 'nan')].index):\n",
    "                    df[i].iloc[a] = np.nan\n",
    "            for i in range(df.shape[0]):\n",
    "                try:\n",
    "                    df.loc[i,'Piętro'] = df.loc[i,'Piętro'].split('/')[0].replace('parter','0').replace('poddasze', '11').replace('suterena', '12').replace('> ','')\n",
    "                except:\n",
    "                    df.loc[i,'Piętro'] = df.loc[i,'Piętro'].replace('parter','0').replace('poddasze', '11').replace('suterena', '12').replace('> ','')\n",
    "\n",
    "            df = df[df['Cena'] != 'Zapytaj o cenę']\n",
    "            df = df.dropna(subset=['Cena'])\n",
    "            df['Cena'] = df['Cena'].astype('str').apply(lambda x: ''.join(c for c in x if c.isdigit()))\n",
    "            df['Cena'] = df['Cena'].astype('str').apply(lambda x: ''.join(c for c in x if ((c.isdigit())| (c=='.'))))\n",
    "            df['Powierzchnia'] = df['Powierzchnia'].astype('str').apply(lambda x: ''.join(c for c in x if (c.isdigit())|(c=='.')))\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            #missing values\n",
    "            index_NaN_rok_pierwotny = list(df[(df[\"Rok budowy\"].isnull()) & (df['Rynek'] == 'pierwotny')].index)\n",
    "            index_NaN_rok_wtorny = list(df[(df[\"Rok budowy\"].isnull()) & (df['Rynek'] == 'wtórny')].index)\n",
    "            index_NaN_rok_nan = list(df[(df[\"Rok budowy\"].isnull()) & (df['Rynek'] != 'wtórny')& (df['Rynek'] != 'pierwotny')].index)\n",
    "\n",
    "            for i in index_NaN_rok_pierwotny :\n",
    "                rok_med = df[\"Rok budowy\"][df['Rynek']=='pierwotny'].median()\n",
    "                df['Rok budowy'].iloc[i] = rok_med\n",
    "\n",
    "            for i in index_NaN_rok_wtorny :\n",
    "                rok_med = df[\"Rok budowy\"][df['Rynek']=='wtórny'].median()\n",
    "                df['Rok budowy'].iloc[i] = rok_med\n",
    "\n",
    "            for i in index_NaN_rok_nan :\n",
    "                rok_med = df[\"Rok budowy\"].median()\n",
    "                df['Rok budowy'].iloc[i] = rok_med\n",
    "\n",
    "            df['Rok budowy'] = df['Rok budowy'].astype('int64')\n",
    "            df['Cena'] = df['Cena'].astype('float64')\n",
    "            df['Piętro'] = df['Piętro'].astype('int64')\n",
    "            df['Powierzchnia'] = df['Powierzchnia'].astype('float64')\n",
    "            df['Cena_m2'] = df['Cena']/df['Powierzchnia']\n",
    "            df = df.drop(columns=['Cena'])\n",
    "            # wysoka korelacja ze zmienną 'Powierzchnia', ponad 0.7\n",
    "            df = df.drop(columns=['Liczba pokoi'])\n",
    "\n",
    "            final_df = self.remove_outliers(self.fill_na(df))\n",
    "\n",
    "            with open(\"cleaned_data_\"+ self.month +'_'+ self.city + \".pickle\", \"wb\") as output_file:\n",
    "                    pickle.dump(final_df, output_file)\n",
    "        return final_df\n",
    "\n",
    "        \n",
    "    def remove_outliers(self, data):\n",
    "        df = data\n",
    "        for x in df.select_dtypes(include=['float','int64']).columns:\n",
    "            # calculate summary statistics\n",
    "            data_mean, data_std = np.mean(df[x]), np.std(df[x])\n",
    "            # identify outliers\n",
    "            cut_off = data_std * 3\n",
    "            lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "\n",
    "            df = df[(df[x] > lower)&(df[x] < upper)]\n",
    "\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        return df\n",
    "        \n",
    "    def fill_na(self, data):\n",
    "        \n",
    "        df = data\n",
    "        \n",
    "        # za dużo NA\n",
    "        df = df.drop(columns=['Materiał budynku','Rodzaj zabudowy','Czynsz', 'Ogrzewanie','Forma własności'])\n",
    "        \n",
    "        # rok budowy dla wartosci NA wynosi mniej niż 2020/21/22 dlatego możemy uznać, że jest to rynek wtórny\n",
    "        for i in list(df[(df['Rynek'].isna())].index):\n",
    "            df['Rynek'].iloc[i] = 'wtórny'\n",
    "\n",
    "        # rynek pierwotny w większosci przypadków ma stan do wykonczenia\n",
    "        for i in list(df[(df['Rynek']=='pierwotny') & (df['Stan wykończenia'].isna())].index):\n",
    "            df['Stan wykończenia'].iloc[i] = 'do wykończenia'\n",
    "\n",
    "        # brakujace wartosci zmiennej 'Stan wykonczenia' uzupelniam na podstawie mediany roku budowy\n",
    "        r_median = df[df['Rynek']=='wtórny'].groupby('Stan wykończenia')['Rok budowy'].median()['do remontu']\n",
    "        z_median = df[df['Rynek']=='wtórny'].groupby('Stan wykończenia')['Rok budowy'].median()['do zamieszkania']\n",
    "        w_median = df[df['Rynek']=='wtórny'].groupby('Stan wykończenia')['Rok budowy'].median()['do wykończenia']\n",
    "        for i in list(df[(df['Stan wykończenia'].isna()) & (df['Rok budowy']>= (w_median+z_median)/2)].index):\n",
    "            df['Stan wykończenia'].iloc[i] = 'do wykończenia'\n",
    "\n",
    "        for i in list(df[(df['Stan wykończenia'].isna()) & (df['Rok budowy']< (w_median+z_median)/2) & (df['Rok budowy']>= (r_median+z_median)/2)].index):\n",
    "            df['Stan wykończenia'].iloc[i] = 'do zamieszkania'\n",
    "\n",
    "        for i in list(df[(df['Stan wykończenia'].isna()) & (df['Rok budowy']< (r_median+z_median)/2)].index):\n",
    "            df['Stan wykończenia'].iloc[i] = 'do remontu'\n",
    "            \n",
    "        return df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "463aa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_the_data(month='March', city='warszawa').get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b81ae1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(frac=1)[:1000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154bb40",
   "metadata": {},
   "source": [
    "# Budowa modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aca4fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_model(data):\n",
    "    \n",
    "    X = data.drop(columns=['Cena_m2'])\n",
    "    y = data['Cena_m2']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    models = [('LR',LinearRegression()), ('LASSO', Lasso()), ('EN', ElasticNet()), ('KNN', KNeighborsRegressor()),\n",
    "              ('CART', DecisionTreeRegressor()), ('GBR', GradientBoostingRegressor()), ('XGB', XGBRegressor()),\n",
    "             ('RF', RandomForestRegressor())]\n",
    "    categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, ['Rok budowy','Powierzchnia']),\n",
    "            ('cat', categorical_transformer, categorical_features),\n",
    "        ])\n",
    "    \n",
    "    results = []\n",
    "    names = []\n",
    "    pipelines = []\n",
    "    for i in models:\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('poly', PolynomialFeatures(degree=4)),\n",
    "                       ('pca', pca),\n",
    "                       i\n",
    "                       ])\n",
    "        pipelines.append(pipeline)\n",
    "        names.append(i[0])\n",
    "        \n",
    "    for model in pipelines:\n",
    "        kfold = KFold(n_splits=5, random_state=21, shuffle=True)\n",
    "        cv_results = cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "        results.append([round(cv_results.mean(),2), round(cv_results.std(),2)])\n",
    "    \n",
    "    df_results = pd.DataFrame(data=results, index=names, columns=['MAE', 'STD'])\n",
    "\n",
    "       \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b31be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = choose_best_model(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bdc9fe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>-1.035331e+12</td>\n",
       "      <td>1.066739e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-2.744090e+03</td>\n",
       "      <td>7.329000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>-1.847960e+03</td>\n",
       "      <td>1.968400e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>-1.891890e+03</td>\n",
       "      <td>1.533700e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CART</th>\n",
       "      <td>-2.354290e+03</td>\n",
       "      <td>1.528600e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR</th>\n",
       "      <td>-1.853600e+03</td>\n",
       "      <td>9.950000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>-1.941890e+03</td>\n",
       "      <td>1.154300e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-1.809010e+03</td>\n",
       "      <td>1.290700e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MAE           STD\n",
       "LR    -1.035331e+12  1.066739e+12\n",
       "LASSO -2.744090e+03  7.329000e+02\n",
       "EN    -1.847960e+03  1.968400e+02\n",
       "KNN   -1.891890e+03  1.533700e+02\n",
       "CART  -2.354290e+03  1.528600e+02\n",
       "GBR   -1.853600e+03  9.950000e+01\n",
       "XGB   -1.941890e+03  1.154300e+02\n",
       "RF    -1.809010e+03  1.290700e+02"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wybieram GradientBoostingRegressor -> najniższe std oraz niski MAE\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2afe8",
   "metadata": {},
   "source": [
    "Tworzenie pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bec6cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sample.drop(columns=['Cena_m2'])\n",
    "y = df_sample['Cena_m2']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, ['Rok budowy','Powierzchnia']),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "                             criterion='mse',\n",
    "                            )\n",
    "pca = PCA()\n",
    "dt = DecisionTreeRegressor(max_depth=12)\n",
    "svr_rbf=SVR(C=1.0, epsilon=0.2, kernel='rbf')\n",
    "xgb = XGBRegressor()\n",
    "lr = LinearRegression()\n",
    "knn = KNeighborsRegressor()\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('poly', PolynomialFeatures(degree=4)),\n",
    "                       ('pca', pca),\n",
    "                       ('model', gb)\n",
    "                       ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e51eb0",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aac28b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_parms = {'model__max_depth':[1,3,5], 'model__n_estimators':[20,50,100,200], 'model__alpha':[0.3,0.5,0.9,1.5]}\n",
    "gd = GridSearchCV(pipe, gb_parms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "830e9864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.24639540422580297, 2063.652707237465)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "032193a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Rok budowy',\n",
       "                                                   'Powierzchnia']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['Rynek', 'Stan wykończenia', 'Lokalizacja', 'Miasto'], dtype='object'))])),\n",
       "                ('poly', PolynomialFeatures(degree=4)), ('pca', PCA()),\n",
       "                ('model',\n",
       "                 GradientBoostingRegressor(alpha=0.3, n_estimators=50))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e265276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb2 = gd.best_estimator_['model']\n",
    "\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('poly', PolynomialFeatures(degree=4)),\n",
    "                       ('pca', pca),\n",
    "                       ('model', gb2)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5945bbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1882.9724714234358, 110.1484538567394)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_sample.drop(columns=['Cena_m2'])\n",
    "y = df_sample['Cena_m2']\n",
    "kfold = KFold(n_splits=5, random_state=21, shuffle=True)\n",
    "cv_results_final = cross_val_score(pipe, X, y, cv=kfold, scoring='neg_mean_absolute_error')\n",
    "cv_results_final.mean(), cv_results_final.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e047c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5271641242553218"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_final_r2 = cross_val_score(pipe, X, y, cv=kfold, scoring='r2')\n",
    "cv_results_final_r2.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
